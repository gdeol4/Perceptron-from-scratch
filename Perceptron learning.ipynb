{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Briefly, what is a perceptron?\n",
    "\n",
    "A neuron is the basic functioning unit of the brain, similarly a perceptron is the basic functioning unit of a neural network. In this post I’ll briefly cover the similarities between artificial and biological neural networks, the theory behind how perceptrons work, and lastly how to implement the algorithm in python to train it on a bioconcentration data set.\n",
    "\n",
    "In animals, a neuron receives input from the synapses of other neurons at its dendrites. These tree like structures take the input signals and amalgamate them in the cell body, also known as a soma. Once the summation of signals happens in the soma, gated ion channels will open or remain closed depending on whether the signal breaches a threshold value — causing the neuron to fire along the axon or remain static. The neuron either fires or it doesn’t.\n",
    "\n",
    "<img src=\"perceptron.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few components in the image I put together above that we should go over to understand the model better:\n",
    "    \n",
    "### Input & bias: \n",
    "The dendrite of the biological neuron accepts input as neurotransmitters from connecting synapses. The counterpart in the perceptron model is the input (a feature used for the classification) multiplied by it’s respective weight. The weights are values which change over time when training the model as they update in the “learning” phase when an error occurs during training. A bias is added as a special input to shift the decision boundary by translating points left or right. The summation equation below shows how the inputs, weights, and bias fit together.\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"summation.png\">\n",
    "<br>\n",
    "<br>\n",
    "In the image below is a sigmoid curve and if we were to change the weights we could alter the steepness of the slope but to actually shift the curve left or right you would need to add a bias. Translating all the points in a certain direction using bias can increase accuracy by helping separate the hyperplane.\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"sigmoid.jpeg\">\n",
    "<br>\n",
    "<br>\n",
    "***\n",
    "### Activation function: \n",
    "The summation of excitatory and inhibiting ions in the soma of a neuron results in an action potential. If the action potential is excitatory and breaches the threshold value — a signal is fired. In an artificial neuron the activation function calculates the net output of the summed inputs. The perceptron is effectively the model’s decision maker and uses the heaviside function, which is also known as a step function, to calculate a predicted binary output. Below is the step function that is most commonly used:\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"stepfunc.png\">\n",
    "<br>\n",
    "<br>\n",
    "    θ is the activation function\n",
    "    <br>\n",
    "    z is the sum of the inputs multiplied by their weights (and bias if included)\n",
    "<br>\n",
    "<br>\n",
    "***\n",
    "\n",
    "### Output: \n",
    "The biological neuron propagates a signal down it’s axon if the threshold is reached, this is it’s output. A perceptron’s output too fires on an all or nothing basis and results in a binary classification of either 1 or -1.\n",
    "\n",
    "**Note:** A more in depth article on this material can be found here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step by step algorithm\n",
    "\n",
    "The following is a rundown of the steps taken by the algorithm to predict and then learn.\n",
    "\n",
    "    1. Set weights to small initial values\n",
    "    2. Multiply the input and weight vectors then sum them up\n",
    "    3. If the the summed value is greater than the threshold then a binary output will be computed\n",
    "    4. Check to see if the predicted outcome was correct and then update weights accordingly\n",
    "    5. Repeat the process for increased accuracy\n",
    "\n",
    "Note: Another great article explaining why the algorithm works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding the perceptron\n",
    "\n",
    "**Note:** I’ll be dissecting and explaining code examples from the book “Python Machine Learning” while mixing in code of my own. I’ll be going over each line of code for our perceptron.\n",
    "\n",
    "The very first line of code will import numpy since we need to perform vector multiplication and draw on random numbers. We then create the perceptron class and initialize it and set parameter values for “epochs”, “learning_rate”, and randomState.\n",
    "<br>\n",
    "<br>\n",
    "**epochs**— the number of times all training data is passed forward and backwards\n",
    "<br>\n",
    "<br>\n",
    "**learning rate** — usually referred to as η (eta) and step size. This value updates the weights. When training  the data, the weights will be updated according to how much error they're responsible for, however the learning rate updates the weights with a fraction of this error. So weights are updated as such — weight + η(error).\n",
    "<br>\n",
    "<br>\n",
    "**randomState**— is used a class for drawing pseudo random generated numbers for an instance. I’d advise against using random.seed() since it will impact the global numpy environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, epochs = 100, learning_rate = 0.01, randomState = 42):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.randomState = randomState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the fit function which takes x and y arguments.\n",
    "<br>\n",
    "<br>\n",
    "**weights**— this parameter is used to set the weights to a random number instead of zero. Having zero as the starting weights causes a problem of symmetry. If the weight of all input values is zero then the error will also be zero and they will all be updated with the same magnitude. We generate a normal distribution with a mean of 0, a standard deviation of 0.01 and a draw size of 1 sample.\n",
    "<br>\n",
    "<br>\n",
    "**errors**— is an empty list that we will append with errors we catch during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, epochs = 100, learning_rate = 0.01, randomState = 42):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.randomState = randomState\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        rgen = np.random.RandomState(self.randomState)\n",
    "        self.weights = rgen.normal(loc=0.0, scale=0.01, size=1 + x.shape[1])\n",
    "        self.errors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next chunk of code is a loop that falls within the fit function that we just defined. However, we’ll look at it separately line-by-line due to its many parts.\n",
    "\n",
    "    1. we set the loop to iterate through each epoch\n",
    "    2. set the error variable to 0 for each iteration\n",
    "    3. here xi and target are two numbers in a tuple of x and y values that we input as our data\n",
    "    4. set the update variable as the value we need to update our weights with, which is learning rate * the error\n",
    "    5. the weights of the inputs are updated with the following formula: eights = weights + (update * xi)\n",
    "    6. here we update the bias input as: weight = weight + update\n",
    "    7. we now set the value of the errors variable as the update value\n",
    "    8. lastly we append the list of errors we created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, epochs = 100, learning_rate = 0.01, randomState = 42):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.randomState = randomState\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        rgen = np.random.RandomState(self.randomState)\n",
    "        self.weights = rgen.normal(loc=0.0, scale=0.01, size=1 + x.shape[1])\n",
    "        self.errors = []\n",
    "    \n",
    "        for i in range(self.epochs):\n",
    "            errors = 0\n",
    "            for xi, target in zip(x, y):\n",
    "                update = self.learning_rate * (target - self.predict(xi))\n",
    "                self.weights[1:] += update * xi\n",
    "                self.weights[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors.append(errors)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last block of the perceptron code will define the summation and prediction functions.\n",
    "<br>\n",
    "<br>\n",
    "**summation**— we define our feature inputs as x and return the vector dot product of the weights and the inputs, along with the bias unit.\n",
    "<br>\n",
    "<br>\n",
    "**predict**— using x (feature input) as the function argument, the function returns the 1 if summation(x) is greater than 0; -1 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, epochs = 100, learning_rate = 0.01, randomState = 42):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.randomState = randomState\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        rgen = np.random.RandomState(self.randomState)\n",
    "        self.weights = rgen.normal(loc=0.0, scale=0.01, size=1 + x.shape[1])\n",
    "        self.errors = []\n",
    "    \n",
    "        for i in range(self.epochs):\n",
    "            errors = 0\n",
    "            for xi, target in zip(x, y):\n",
    "                update = self.learning_rate * (target - self.predict(xi))\n",
    "                self.weights[1:] += update * xi\n",
    "                self.weights[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors.append(errors)\n",
    "        return self\n",
    "\n",
    "    def summation(self, x):\n",
    "        return np.dot(x, self.weights[1:]) + self.weights[0]\n",
    "    def predict(self, x):\n",
    "        return np.where(self.summation(x) >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and preparing the data\n",
    "\n",
    "I chose not to go with the classic data sets like Fisher’s iris data set and rather chose to find one relevant to the work I’m currently doing. This led me to a bioconcentration data set hosted by the University of Milano-Bicocca and can be found here (http://www.michem.unimib.it/download/data/mechanisms-of-bioconcentration/).\n",
    "\n",
    "The data only needs a bit of touching up and is otherwise ready to use. In the following block of code is what I did to make the data usable with the perceptron model. The original data comes with 3 different classifications: (1) is mainly stored within lipid tissues, (2) has additional storage sites (e.g. proteins), or (3) is metabolized/eliminated [1]. Since our model will work with two prediction classes we can drop the (2) class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAS</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>logBCF</th>\n",
       "      <th>logKOW</th>\n",
       "      <th>nHM</th>\n",
       "      <th>piPC09</th>\n",
       "      <th>PCD</th>\n",
       "      <th>X2Av</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>ON1V</th>\n",
       "      <th>N-072</th>\n",
       "      <th>B02[C-N]</th>\n",
       "      <th>F04[C-O]</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100-02-7</td>\n",
       "      <td>O=[N+](c1ccc(cc1)O)[O-]</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100-17-4</td>\n",
       "      <td>O=[N+](c1ccc(cc1)OC)[O-]</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100-18-5</td>\n",
       "      <td>c1cc(ccc1C(C)C)C(C)C</td>\n",
       "      <td>3.24</td>\n",
       "      <td>5.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4.14</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100-25-4</td>\n",
       "      <td>O=[N+]([O-])c1ccc(cc1)[N+](=O)[O-]</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100-40-3</td>\n",
       "      <td>C=CC1CCC=CC1</td>\n",
       "      <td>2.24</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CAS                              SMILES  logBCF  logKOW  nHM  piPC09  \\\n",
       "0  100-02-7             O=[N+](c1ccc(cc1)O)[O-]    0.74    1.91    0     0.0   \n",
       "1  100-17-4            O=[N+](c1ccc(cc1)OC)[O-]    0.93    2.03    0     0.0   \n",
       "2  100-18-5                c1cc(ccc1C(C)C)C(C)C    3.24    5.23    0     0.0   \n",
       "3  100-25-4  O=[N+]([O-])c1ccc(cc1)[N+](=O)[O-]   -0.40    1.46    0     0.0   \n",
       "4  100-40-3                        C=CC1CCC=CC1    2.24    3.93    0     0.0   \n",
       "\n",
       "    PCD  X2Av  MLOGP  ON1V  N-072  B02[C-N]  F04[C-O]  Class  \n",
       "0  1.49  0.14   1.35  0.72      0         1         5      1  \n",
       "1  1.47  0.14   1.70  0.88      0         1         5      1  \n",
       "2  1.20  0.25   4.14  2.06      0         0         0     -1  \n",
       "3  1.69  0.13   1.89  0.79      0         1         8     -1  \n",
       "4  0.52  0.25   2.65  1.31      0         0         0      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "#data = pd.read_csv(r\"C:/Path/to/file/bcf_data.csv\")\n",
    "\n",
    "#drop all rows with a class 2 label\n",
    "data = data.drop(data[data.Class == 2].index)\n",
    "\n",
    "#replace the 3 class label with -1\n",
    "data['Class'] = data['Class'].map({1: 1, 3: -1})\n",
    "\n",
    "#drop the predefined set id\n",
    "data = data.drop(\"Set\", axis = 1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our training data set to train the perceptron learning model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#we seperate the class labels from the original dataframe\n",
    "y=data.Class\n",
    "\n",
    "#we need to drop the non-predictor columns and extract predictive features\n",
    "x=data.drop(['Class', 'SMILES', 'CAS'], axis=1)\n",
    "\n",
    "#using scikit learn we can easily partition our data and train the model with 85% of the data\n",
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.15)\n",
    "\n",
    "#in order to train the model we need to get a series of just the values from the dataframe\n",
    "x2 = x_train.iloc[0:607, [0,1,2,3,4,5,6,7,8,9,10]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the perceptron\n",
    "\n",
    "This data set was chosen on a whim, and for a classifier to be as accurate as possible, the predictive features should be able to separate the groups along a plane. We could perform a PCA or another form of dimension reduction to figure out the most important features but that isn't the focus of this tutorial. The point is to see a if we can write and train a perceptron on a given set of classification data and how it performs on that data. The code block below plots the results for our training and looks at the number of updates over epochs — how much adjustment we have to perform over passes on the entire training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#after a few trial and error runs I stuck to these parameter values\n",
    "perceptron_model = Perceptron(learning_rate = 0.25, epochs = 30)\n",
    "\n",
    "#training the model\n",
    "perceptron_model.fit(x2, y_train)\n",
    "\n",
    "#modules needed for plotting the updates over epochs\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#plotting the number of updates over epochs\n",
    "plt.plot(range(1, len(perceptron_model.errors) + 1), perceptron_model.errors, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of updates')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Not great, but it works!\n",
    "\n",
    "We see that although the number of updates oscillates, there is a general downward trend over iterations, that is to say, our perceptron algorithm is getting more accurate with each pass over the training data. We can’t say that it will reach zero (as it would with a less complex data set such as Fisher’s Iris) but we can say that our simple perceptron learning algorithm — from the 1960’s — did indeed “learn”.\n",
    "\n",
    "### References\n",
    "\n",
    "[1] F. Grisoni, V.Consonni, M.Vighi, S.Villa, R.Todeschini, Investigating the mechanisms of bioconcentration through QSAR classification trees (2016), Environment International"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
